{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNGAx0jgDUQ/GN3RzNzkgcP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cnhzgb/MachineL/blob/main/VGG11_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb\n",
        "!pip install einops\n",
        "import ipdb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "hofQlMWWYHNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c120d148-dc9e-498e-8d8e-86ff69722124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.0.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JyY7NuECDB4"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "trans = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) # transforms.RandomHorizontalFlip(), transforms.RandomGrayscale()\n",
        "dataset = datasets.CIFAR10(root=\"dataset/\", transform=trans, download=True, train=True) # 5W张图片, 10种分类\n",
        "loader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "batch_num,(image, label) = next(enumerate(loader))\n",
        "print(len(dataset.classes), len(dataset), image.shape, label.shape) # 10; 5W; 100,3,32,32; 100\n",
        "\n",
        "trans_test = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "dataset_test = datasets.CIFAR10(root=\"dataset/\", transform=trans_test, download=True, train=False) # 1W张图片\n",
        "loader_test = DataLoader(dataset_test, batch_size=100, shuffle=True)\n",
        "criterion_test = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://zhuanlan.zhihu.com/p/87555358\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,64,3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3,padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, 3,padding=1)\n",
        "        self.conv7 = nn.Conv2d(256, 256, 3,padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv8 = nn.Conv2d(256, 512, 3,padding=1)\n",
        "        self.conv9 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.conv11 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv13 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.pool5 = nn.MaxPool2d(2, 2)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.fc14 = nn.Linear(512*7*7,4096)\n",
        "        self.fc15 = nn.Linear(4096,4096)\n",
        "        self.fc16 = nn.Linear(4096,10)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x)) # => ,64,224,224\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x) # => ,64,112,112\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x)) # => ,128,112,112\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x) # => ,128,56,56\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x = F.relu(self.conv5(x)) # => ,256,56,56\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.pool3(x) # => ,256,28,28\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        x = F.relu(self.conv8(x)) # => ,512,28,28\n",
        "        x = F.relu(self.conv9(x))\n",
        "        x = F.relu(self.conv10(x))\n",
        "        x = self.pool4(x) # => ,512,14,14\n",
        "        x = self.bn4(x)\n",
        "\n",
        "        x = F.relu(self.conv11(x)) # => ,512,14,14\n",
        "        x = F.relu(self.conv12(x))\n",
        "        x = F.relu(self.conv13(x))\n",
        "        x = self.pool5(x) # => ,512,7,7\n",
        "        x = self.bn5(x)\n",
        "\n",
        "        x = x.view(-1,512*7*7)\n",
        "        x = F.relu(self.fc14(x)) # => 4096\n",
        "        x = F.dropout(x, p=0.5)\n",
        "        x = F.relu(self.fc15(x)) # => 4096\n",
        "        x = F.dropout(x, p=0.5)\n",
        "        x = self.fc16(x) # => 10\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)"
      ],
      "metadata": {
        "id": "Fm-vKBCpQ966"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,10):\n",
        "  total_loss = []\n",
        "  errorTotal = 0\n",
        "  for batch_idx, (img, label) in enumerate(loader):\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "    outputs = model(img)\n",
        "    loss = criterion(outputs, label)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss.append(loss.item())\n",
        "    maxV,maxIdx = outputs.max(dim=1)\n",
        "    errorNum = torch.sum(torch.ne(maxIdx, label)).item()\n",
        "    errorTotal += errorNum\n",
        "\n",
        "    if(batch_idx % 100 == 99):\n",
        "      print(\"epoch:{} batch:{} loss:{:.2f} mean:{:.2f} error:{}/100 errorTotal:{}/{} {:.2f}%\".format(\n",
        "          epoch, batch_idx, loss, np.mean(total_loss), errorNum, errorTotal, (batch_idx+1)*100, errorTotal/(batch_idx+1)))"
      ],
      "metadata": {
        "id": "efm8ASvZX9DS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}