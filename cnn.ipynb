{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-with-pytorch - 4 [CNN].ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bIAYbYajk1w9"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks\n",
        "- CIFAR-10 image classification with CNN\n",
        "  - Last time, we have attempted to classify images in the CIFAR-10 dataset with MLP and deeper MLP. The final results were accuracy scores of 0.369 and 0.504, respectively.\n",
        "  - Let's try to improve the classification performance by implementing simple CNN"
      ]
    },
    {
      "metadata": {
        "id": "GVU5-yp3N89I"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision\n",
        "!pip install ipdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8yy37hEYOEiQ"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import ipdb"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ewrw93tt2BfV"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Import & process dataset\n",
        "- CIFAR10 dataset can be downloaded by ```torchvision```\n",
        "  - [torchvision.datasets](https://pytorch.org/docs/stable/torchvision/datasets.html)"
      ]
    },
    {
      "metadata": {
        "id": "W5anlYa01w3w"
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root = \"/\", train = True, download = True, transform = transforms.ToTensor())\n",
        "test_dataset = datasets.CIFAR10(root = \"/\", train = False, download = True, transform = transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "print(len(train_dataset))\n",
        "print(train_dataset.classes)\n",
        "img, label = train_dataset[random.randint(0,len(train_dataset))]\n",
        "#print(img)\n",
        "print(img.shape)\n",
        "print(label,' - ', train_dataset.classes[label])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "img0 = torchvision.utils.make_grid(img)\n",
        "img1 = img0 / 2 + 0.5\n",
        "img2 = img1.numpy()\n",
        "img3 = np.transpose(img2, (1,2,0))\n",
        "print(img3.shape)\n",
        "plt.imshow(img3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "VBQrv6EXf2Le",
        "outputId": "ef18974e-086c-4df3-ed43-7565a3ea8d50"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "torch.Size([3, 32, 32])\n",
            "3  -  cat\n",
            "(32, 32, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc150dcd330>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "9nznVMdo5edZ"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Creating CNN model and training\n",
        "\n",
        "- Create and train simple CNN model\n",
        "\n",
        "![](https://www.researchgate.net/profile/Qianzhou_Du2/publication/322477802/figure/fig3/AS:582461356511232@1515881017676/Illustration-of-Convolutional-Neural-Network-CNN-Architecture.png)"
      ]
    },
    {
      "metadata": {
        "id": "YEoNQr10kGUW"
      },
      "cell_type": "code",
      "source": [
        "# create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 128, shuffle = False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQawpMRPI7jm"
      },
      "cell_type": "code",
      "source": [
        "# create CNN with one convolution/pooling layer\n",
        "class net(nn.Module):\n",
        "  def __init__(self, input_dim, num_filters, kernel_size, stride, padding, num_classes):\n",
        "    super(net, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    conv_output_size = int((input_dim - kernel_size + 2 * padding)/stride) + 1   # conv layer output size\n",
        "    pool_output_size = int((conv_output_size - kernel_size)/stride) + 1          # pooling layer output size\n",
        "\n",
        "    self.conv = nn.Conv2d(3, num_filters, kernel_size = kernel_size, stride = stride, padding = padding)\n",
        "    self.pool = nn.MaxPool2d(kernel_size = kernel_size, stride = stride)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dense = nn.Linear(pool_output_size * pool_output_size * num_filters, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = x.view(x.size(0), -1)   # resize to fit into final dense layer\n",
        "    x = self.dense(x)\n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rP0Gt5E9ajmd"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "DEVICE = torch.device('cuda')\n",
        "INPUT_DIM = 32\n",
        "NUM_FILTERS = 32\n",
        "KERNEL_SIZE = 3\n",
        "STRIDE = 1\n",
        "PADDING = 1\n",
        "NUM_CLASSES = 10\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_EPOCHS = 30"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cPBm8qDrSWsi"
      },
      "cell_type": "code",
      "source": [
        "model = net(INPUT_DIM, NUM_FILTERS, KERNEL_SIZE, STRIDE, PADDING, NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()   # do not need softmax layer when using CEloss criterion\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SEBtAPYCFeic",
        "outputId": "2024b6ca-b3f7-4473-e34f-2ef7f2406304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "cell_type": "code",
      "source": [
        "# training for NUM_EPOCHS\n",
        "for i in range(NUM_EPOCHS):\n",
        "  temp_loss = []\n",
        "  for (x, y) in train_loader:\n",
        "    x, y = x.float().to(DEVICE), y.to(DEVICE)\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y)\n",
        "    temp_loss.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"Loss at {}th epoch: {}\".format(i, np.mean(temp_loss)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at 0th epoch: 1.5712974797124448\n",
            "Loss at 1th epoch: 1.1810427417840494\n",
            "Loss at 2th epoch: 1.0656654142662692\n",
            "Loss at 3th epoch: 0.9980279734677366\n",
            "Loss at 4th epoch: 0.9477736516986661\n",
            "Loss at 5th epoch: 0.9076264293297477\n",
            "Loss at 6th epoch: 0.8745927472248711\n",
            "Loss at 7th epoch: 0.8494284117923063\n",
            "Loss at 8th epoch: 0.8183362279706599\n",
            "Loss at 9th epoch: 0.7914504044501068\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c5803881aada>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtemp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0m__array_interface__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArrayData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qpAJUiHm529m"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Evaluation\n",
        "- Evaluate the trained CNN model with accuracy score\n",
        "  - Store probability of each instance to a list and compare it with true y label"
      ]
    },
    {
      "metadata": {
        "id": "txXH3dknFpSx",
        "outputId": "d1db27e2-f9ca-4642-971e-98ab60a352f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred, y_true = [], []\n",
        "with torch.no_grad():\n",
        "  for x, y in test_loader:\n",
        "    x, y = x.float().to(DEVICE), y.to(DEVICE)\n",
        "    outputs = F.softmax(model(x)).max(1)[-1]       # predicted label\n",
        "    y_true += list(y.cpu().numpy())                # true label\n",
        "    y_pred += list(outputs.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HV1s3xf5Frkl",
        "outputId": "8c2be308-ea59-46d7-879f-dee1bde8f264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# evaluation result\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}