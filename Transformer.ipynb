{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cnhzgb/MachineL/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIIAGxzT8h_t"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils import data as Data\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSMxTYJzWhXH"
      },
      "source": [
        "d_model = 512 # embedding size\n",
        "max_len = 1024 # max length of sequence\n",
        "d_ff = 2048 # feedforward nerual network  dimension\n",
        "d_k = d_v = 64 # dimension of k(same as q) and v\n",
        "n_layers = 6 # number of encoder and decoder layers\n",
        "n_heads = 8 # number of heads in multihead attention\n",
        "p_drop = 0.1 # propability of dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgvM4Rx1LF0A"
      },
      "source": [
        "def get_attn_pad_mask(seq_q, seq_k):\n",
        "  '''\n",
        "  Padding, because of unequal in source_len and target_len.\n",
        "\n",
        "  parameters:\n",
        "  seq_q: [batch, seq_len]\n",
        "  seq_k: [batch, seq_len]\n",
        "\n",
        "  return:\n",
        "  mask: [batch, len_q, len_k]\n",
        "\n",
        "\n",
        "  '''\n",
        "  batch, len_q = seq_q.size()\n",
        "  batch, len_k = seq_k.size()\n",
        "  # we define index of PAD is 0, if tensor equals (zero) PAD tokens\n",
        "  pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) # [batch, 1, len_k]\n",
        "\n",
        "  return pad_attn_mask.expand(batch, len_q, len_k) # [batch, len_q, len_k]\n",
        "\n",
        "def get_attn_subsequent_mask(seq):\n",
        "  '''\n",
        "  Build attention mask matrix for decoder when it autoregressing.\n",
        "\n",
        "  parameters:\n",
        "  seq: [batch, target_len]\n",
        "\n",
        "  return:\n",
        "  subsequent_mask: [batch, target_len, target_len]\n",
        "  '''\n",
        "  attn_shape = [seq.size(0), seq.size(1), seq.size(1)] # [batch, target_len, target_len]\n",
        "  subsequent_mask = np.triu(np.ones(attn_shape), k=1) # [batch, target_len, target_len]\n",
        "  subsequent_mask = torch.from_numpy(subsequent_mask)\n",
        "\n",
        "  return subsequent_mask # [batch, target_len, target_len]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMzZlZrnlO_I"
      },
      "source": [
        "$$\n",
        "PE(pos, 2i) = \\sin(pos / 10000^{\\frac{2i}{d_{model}}}) \\\\\n",
        "PE(pos, 2i+1) = \\cos(pos / 10000^{\\frac{2i}{d_{model}}})\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoJxqjC28wcW"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "  def __init__(self, d_model, dropout=.1, max_len=1024):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=p_drop)\n",
        "\n",
        "    positional_encoding = torch.zeros(max_len, d_model) # [max_len, d_model]\n",
        "    position = torch.arange(0, max_len).float().unsqueeze(1) # [max_len, 1]\n",
        "\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
        "                         (-torch.log(torch.Tensor([10000])) / d_model)) # [max_len / 2]\n",
        "\n",
        "    positional_encoding[:, 0::2] = torch.sin(position * div_term) # even\n",
        "    positional_encoding[:, 1::2] = torch.cos(position * div_term) # odd\n",
        "\n",
        "    # [max_len, d_model] -> [1, max_len, d_model] -> [max_len, 1, d_model]\n",
        "    positional_encoding = positional_encoding.unsqueeze(0).transpose(0, 1)\n",
        "\n",
        "    # register pe to buffer and require no grads\n",
        "    self.register_buffer('pe', positional_encoding)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: [seq_len, batch, d_model]\n",
        "    # we can add positional encoding to x directly, and ignore other dimension\n",
        "    x = x + self.pe[:x.size(0), ...]\n",
        "\n",
        "    return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwX1Y40l9NlT"
      },
      "source": [
        "class Seq2SeqDataset(Data.Dataset):\n",
        "\n",
        "  def __init__(self, encoder_input, decoder_input, decoder_output):\n",
        "    super(Seq2SeqDataset, self).__init__()\n",
        "    self.encoder_input = encoder_input\n",
        "    self.decoder_input = decoder_input\n",
        "    self.decoder_output = decoder_output\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.encoder_input.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.encoder_input[idx], self.decoder_input[idx], self.decoder_output[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQkBW6HzvJMn"
      },
      "source": [
        "$$\n",
        "\\operatorname{Attention}(Q, K, V) = \\operatorname{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa1pO0L4Ji9V"
      },
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "  def forward(self, Q, K, V, attn_mask):\n",
        "    '''\n",
        "    Q: [batch, n_heads, len_q, d_k]\n",
        "    K: [batch, n_heads, len_k, d_k]\n",
        "    V: [batch, n_heads, len_v, d_v]\n",
        "    attn_mask: [batch, n_heads, seq_len, seq_len]\n",
        "    '''\n",
        "    scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # [batch, n_heads, len_q, len_k]\n",
        "    scores.masked_fill_(attn_mask, -1e9)\n",
        "\n",
        "    attn = nn.Softmax(dim=-1)(scores) # [batch, n_heads, len_q, len_k]\n",
        "    prob = torch.matmul(attn, V) # [batch, n_heads, len_q, d_v]\n",
        "    return prob, attn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kor-ycc0KUeY"
      },
      "source": [
        "# x = torch.Tensor([[1, 0, 2, 3], [2, 3, 1, 2]])\n",
        "# mask = torch.BoolTensor([1, 0, 0, 0])\n",
        "# x.masked_fill(mask, -1e9)\n",
        "\n",
        "# x = torch.rand(2, 8, 3, 64)\n",
        "# a, b = ScaledDotProductAttention()(x, x, x, x)\n",
        "# a.size(), b.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PURB9CY0woN4"
      },
      "source": [
        "$$\n",
        "\\begin{aligned}\n",
        "\\operatorname{MultiHead}(Q, K, V) &= \\operatorname{Concat}(\\text{head}_1, \\text{head}_2, \\dots, \\text{head}_h)W^O \\\\\n",
        "\\text{where } \\text{head}_i &= \\operatorname{Attention}(QW^Q_i, KW^K_i, VW^V_i)\n",
        "\\end{aligned}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48HS30HtKjLm"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, n_heads=8):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    # do not use more instance to implement multihead attention\n",
        "    # it can be complete in one matrix\n",
        "    self.n_heads = n_heads\n",
        "\n",
        "    # we can't use bias because there is no bias term in formular\n",
        "    self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
        "    self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
        "    self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
        "    self.fc = nn.Linear(d_v * n_heads, d_model, bias=False)\n",
        "    self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self, input_Q, input_K, input_V, attn_mask):\n",
        "    '''\n",
        "    To make sure multihead attention can be used both in encoder and decoder,\n",
        "    we use Q, K, V respectively.\n",
        "    input_Q: [batch, len_q, d_model]\n",
        "    input_K: [batch, len_k, d_model]\n",
        "    input_V: [batch, len_v, d_model]\n",
        "    '''\n",
        "    residual, batch = input_Q, input_Q.size(0)\n",
        "\n",
        "    # [batch, len_q, d_model] -- matmul W_Q --> [batch, len_q, d_q * n_heads] -- view -->\n",
        "    # [batch, len_q, n_heads, d_k,] -- transpose --> [batch, n_heads, len_q, d_k]\n",
        "\n",
        "    Q = self.W_Q(input_Q).view(batch, -1, n_heads, d_k).transpose(1, 2) # [batch, n_heads, len_q, d_k]\n",
        "    K = self.W_K(input_K).view(batch, -1, n_heads, d_k).transpose(1, 2) # [batch, n_heads, len_k, d_k]\n",
        "    V = self.W_V(input_V).view(batch, -1, n_heads, d_v).transpose(1, 2) # [batch, n_heads, len_v, d_v]\n",
        "\n",
        "    attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # [batch, n_heads, seq_len, seq_len]\n",
        "\n",
        "    # prob: [batch, n_heads, len_q, d_v] attn: [batch, n_heads, len_q, len_k]\n",
        "    prob, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
        "\n",
        "    prob = prob.transpose(1, 2).contiguous() # [batch, len_q, n_heads, d_v]\n",
        "    prob = prob.view(batch, -1, n_heads * d_v).contiguous() # [batch, len_q, n_heads * d_v]\n",
        "\n",
        "    output = self.fc(prob) # [batch, len_q, d_model]\n",
        "\n",
        "    return self.layer_norm(residual + output), attn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXe1VTLzwPTl"
      },
      "source": [
        "$$\n",
        "\\operatorname{FFN}(x)=\\operatorname{ReLU}(xW_1+b_1)W_2 + b_2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEq9OhWXYhoH"
      },
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "  '''\n",
        "  Using nn.Conv1d replace nn.Linear to implements FFN.\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    super(FeedForwardNetwork, self).__init__()\n",
        "    # self.ff1 = nn.Linear(d_model, d_ff)\n",
        "    # self.ff2 = nn.Linear(d_ff, d_model)\n",
        "    self.ff1 = nn.Conv1d(d_model, d_ff, 1)\n",
        "    self.ff2 = nn.Conv1d(d_ff, d_model, 1)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.dropout = nn.Dropout(p=p_drop)\n",
        "    self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: [batch, seq_len, d_model]\n",
        "    residual = x\n",
        "    x = x.transpose(1, 2) # [batch, d_model, seq_len]\n",
        "    x = self.ff1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.ff2(x)\n",
        "    x = x.transpose(1, 2) # [batch, seq_len, d_model]\n",
        "\n",
        "    return self.layer_norm(residual + x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwREm_zUF4FV"
      },
      "source": [
        "# x = torch.rand(1024, 512).unsqueeze(1)\n",
        "# f = FeedForwardNetwork()\n",
        "# f(x).size()\n",
        "\n",
        "# nn.Linear(512, 2048)(x).size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Kz08Y6QdFf"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.encoder_self_attn = MultiHeadAttention()\n",
        "    self.ffn = FeedForwardNetwork()\n",
        "\n",
        "  def forward(self, encoder_input, encoder_pad_mask):\n",
        "    '''\n",
        "    encoder_input: [batch, source_len, d_model]\n",
        "    encoder_pad_mask: [batch, n_heads, source_len, source_len]\n",
        "\n",
        "    encoder_output: [batch, source_len, d_model]\n",
        "    attn: [batch, n_heads, source_len, source_len]\n",
        "    '''\n",
        "    encoder_output, attn = self.encoder_self_attn(encoder_input, encoder_input, encoder_input, encoder_pad_mask)\n",
        "    encoder_output = self.ffn(encoder_output) # [batch, source_len, d_model]\n",
        "\n",
        "    return encoder_output, attn\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.decoder_self_attn = MultiHeadAttention()\n",
        "    self.encoder_decoder_attn = MultiHeadAttention()\n",
        "    self.ffn = FeedForwardNetwork()\n",
        "\n",
        "  def forward(self, decoder_input, encoder_output, decoder_self_mask, decoder_encoder_mask):\n",
        "    '''\n",
        "    decoder_input: [batch, target_len, d_mdoel]\n",
        "    encoder_output: [batch, source_len, d_model]\n",
        "    decoder_self_mask: [batch, target_len, target_len]\n",
        "    decoder_encoder_mask: [batch, target_len, source_len]\n",
        "    '''\n",
        "    # masked mutlihead attention\n",
        "    # Q, K, V all from decoder it self\n",
        "    # decoder_output: [batch, target_len, d_model]\n",
        "    # decoder_self_attn: [batch, n_heads, target_len, target_len]\n",
        "    decoder_output, decoder_self_attn = self.decoder_self_attn(decoder_input, decoder_input, decoder_input, decoder_self_mask)\n",
        "\n",
        "    # Q from decoder, K, V from encoder\n",
        "    # decoder_output: [batch, target_len, d_model]\n",
        "    # decoder_encoder_attn: [batch, n_heads, target_len, source_len]\n",
        "    decoder_output, decoder_encoder_attn = self.encoder_decoder_attn(decoder_input, encoder_output, encoder_output, decoder_encoder_mask)\n",
        "    decoder_output = self.ffn(decoder_output) # [batch, target_len, d_model]\n",
        "\n",
        "    return decoder_output, decoder_self_attn, decoder_encoder_attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.source_embedding = nn.Embedding(source_vocab_size, d_model)\n",
        "    self.positional_embedding = PositionalEncoding(d_model)\n",
        "    self.layers = nn.ModuleList([EncoderLayer() for layer in range(n_layers)])\n",
        "\n",
        "  def forward(self, encoder_input):\n",
        "    # encoder_input: [batch, source_len]\n",
        "    encoder_output = self.source_embedding(encoder_input) # [batch, source_len, d_model]\n",
        "    encoder_output = self.positional_embedding(encoder_output.transpose(0, 1)).transpose(0, 1) # [batch, source_len, d_model]\n",
        "\n",
        "    encoder_self_attn_mask = get_attn_pad_mask(encoder_input, encoder_input) # [batch, source_len, source_len]\n",
        "    encoder_self_attns = list()\n",
        "    for layer in self.layers:\n",
        "      # encoder_output: [batch, source_len, d_model]\n",
        "      # encoder_self_attn: [batch, n_heads, source_len, source_len]\n",
        "      encoder_output, encoder_self_attn = layer(encoder_output, encoder_self_attn_mask)\n",
        "      encoder_self_attns.append(encoder_self_attn)\n",
        "\n",
        "    return encoder_output, encoder_self_attns\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.target_embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "    self.positional_embedding = PositionalEncoding(d_model)\n",
        "    self.layers = nn.ModuleList([DecoderLayer() for layer in range(n_layers)])\n",
        "\n",
        "  def forward(self, decoder_input, encoder_input, encoder_output):\n",
        "    '''\n",
        "    decoder_input: [batch, target_len]\n",
        "    encoder_input: [batch, source_len]\n",
        "    encoder_output: [batch, source_len, d_model]\n",
        "    '''\n",
        "    decoder_output = self.target_embedding(decoder_input) # [batch, target_len, d_model]\n",
        "    decoder_output = self.positional_embedding(decoder_output.transpose(0, 1)).transpose(0, 1) # [batch, target_len, d_model]\n",
        "    decoder_self_attn_mask = get_attn_pad_mask(decoder_input, decoder_input) # [batch, target_len, d_model]\n",
        "    decoder_subsequent_mask = get_attn_subsequent_mask(decoder_input) # [batch, target_len, target_len]\n",
        "\n",
        "    decoder_encoder_attn_mask = get_attn_pad_mask(decoder_input, encoder_input) # [batch, target_len, source_len]\n",
        "\n",
        "    decoder_self_mask = torch.gt(decoder_self_attn_mask + decoder_subsequent_mask, 0)\n",
        "    decoder_self_attns, decoder_encoder_attns = [], []\n",
        "\n",
        "    for layer in self.layers:\n",
        "      # decoder_output: [batch, target_len, d_model]\n",
        "      # decoder_self_attn: [batch, n_heads, target_len, target_len]\n",
        "      # decoder_encoder_attn: [batch, n_heads, target_len, source_len]\n",
        "      decoder_output, decoder_self_attn, decoder_encoder_attn = layer(decoder_output, encoder_output, decoder_self_mask, decoder_encoder_attn_mask)\n",
        "      decoder_self_attns.append(decoder_self_attn)\n",
        "      decoder_encoder_attns.append(decoder_encoder_attn)\n",
        "\n",
        "    return decoder_output, decoder_self_attns, decoder_encoder_attns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0gGS8Cyo8tX",
        "outputId": "d71a8f4c-8d17-4f22-eac8-77bd2703072a"
      },
      "source": [
        "x = torch.Tensor([1, 0, 1, 0])\n",
        "torch.gt(x + torch.Tensor([0, 1, 0, 0]), 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmj9AHqLT0dP"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "    self.projection = nn.Linear(d_model, target_vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, encoder_input, decoder_input):\n",
        "    '''\n",
        "    encoder_input: [batch, source_len]\n",
        "    decoder_input: [batch, target_len]\n",
        "    '''\n",
        "    # encoder_output: [batch, source_len, d_model]\n",
        "    # encoder_attns: [n_layers, batch, n_heads, source_len, source_len]\n",
        "    encoder_output, encoder_attns = self.encoder(encoder_input)\n",
        "    # decoder_output: [batch, target_len, d_model]\n",
        "    # decoder_self_attns: [n_layers, batch, n_heads, target_len, target_len]\n",
        "    # decoder_encoder_attns: [n_layers, batch, n_heads, target_len, source_len]\n",
        "    decoder_output, decoder_self_attns, decoder_encoder_attns = self.decoder(decoder_input, encoder_input, encoder_output)\n",
        "    decoder_logits = self.projection(decoder_output) # [batch, target_len, target_vocab_size]\n",
        "\n",
        "    # decoder_logits: [batch * target_len, target_vocab_size]\n",
        "    return decoder_logits.view(-1, decoder_logits.size(-1)), encoder_attns, decoder_self_attns, decoder_encoder_attns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ls7oA86xe2V"
      },
      "source": [
        "sentences = [\n",
        "        # enc_input           dec_input         dec_output\n",
        "        ['ich mochte ein bier P', 'S i want a beer .', 'i want a beer . E'],\n",
        "        ['ich mochte ein cola P', 'S i want a coke .', 'i want a coke . E']\n",
        "]\n",
        "\n",
        "# Padding Should be Zero\n",
        "source_vocab = {'P' : 0, 'ich' : 1, 'mochte' : 2, 'ein' : 3, 'bier' : 4, 'cola' : 5}\n",
        "source_vocab_size = len(source_vocab)\n",
        "\n",
        "target_vocab = {'P' : 0, 'i' : 1, 'want' : 2, 'a' : 3, 'beer' : 4, 'coke' : 5, 'S' : 6, 'E' : 7, '.' : 8}\n",
        "idx2word = {i: w for i, w in enumerate(target_vocab)}\n",
        "target_vocab_size = len(target_vocab)\n",
        "source_len = 5 # max length of input sequence\n",
        "target_len = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKnTU7W43WdD"
      },
      "source": [
        "def make_data(sentences):\n",
        "  encoder_inputs, decoder_inputs, decoder_outputs = [], [], []\n",
        "  for i in range(len(sentences)):\n",
        "    encoder_input = [source_vocab[word] for word in sentences[i][0].split()]\n",
        "    decoder_input = [target_vocab[word] for word in sentences[i][1].split()]\n",
        "    decoder_output = [target_vocab[word] for word in sentences[i][2].split()]\n",
        "    encoder_inputs.append(encoder_input)\n",
        "    decoder_inputs.append(decoder_input)\n",
        "    decoder_outputs.append(decoder_output)\n",
        "\n",
        "  return torch.LongTensor(encoder_inputs), torch.LongTensor(decoder_inputs), torch.LongTensor(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnqJvO-2hchl"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 32\n",
        "lr = 1e-3\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer().to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "encoder_inputs, decoder_inputs, decoder_outputs = make_data(sentences)\n",
        "dataset = Seq2SeqDataset(encoder_inputs, decoder_inputs, decoder_outputs)\n",
        "data_loader = Data.DataLoader(dataset, 2, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWk7fVkDWsSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c18f7e-c03d-4799-ab0a-e1726b0f5434"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  '''\n",
        "  encoder_input: [batch, source_len]\n",
        "  decoder_input: [batch, target_len]\n",
        "  decoder_ouput: [batch, target_len]\n",
        "  '''\n",
        "  for encoder_input, decoder_input, decoder_output in data_loader:\n",
        "    encoder_input = encoder_input.to(device)\n",
        "    decoder_input = decoder_input.to(device)\n",
        "    decoder_output = decoder_output.to(device)\n",
        "\n",
        "    output, encoder_attns, decoder_attns, decoder_encoder_attns = model(encoder_input, decoder_input)\n",
        "    loss = criterion(output, decoder_output.view(-1))\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss = 2.210672\n",
            "Epoch: 0002 loss = 0.871125\n",
            "Epoch: 0003 loss = 1.653220\n",
            "Epoch: 0004 loss = 1.280224\n",
            "Epoch: 0005 loss = 2.761842\n",
            "Epoch: 0006 loss = 3.543098\n",
            "Epoch: 0007 loss = 3.537732\n",
            "Epoch: 0008 loss = 1.724109\n",
            "Epoch: 0009 loss = 1.223293\n",
            "Epoch: 0010 loss = 1.135749\n",
            "Epoch: 0011 loss = 1.083706\n",
            "Epoch: 0012 loss = 0.908158\n",
            "Epoch: 0013 loss = 0.521601\n",
            "Epoch: 0014 loss = 0.330823\n",
            "Epoch: 0015 loss = 0.268935\n",
            "Epoch: 0016 loss = 0.227477\n",
            "Epoch: 0017 loss = 0.200834\n",
            "Epoch: 0018 loss = 0.209180\n",
            "Epoch: 0019 loss = 0.188584\n",
            "Epoch: 0020 loss = 0.166680\n",
            "Epoch: 0021 loss = 0.157806\n",
            "Epoch: 0022 loss = 0.137217\n",
            "Epoch: 0023 loss = 0.128506\n",
            "Epoch: 0024 loss = 0.127341\n",
            "Epoch: 0025 loss = 0.127648\n",
            "Epoch: 0026 loss = 0.126985\n",
            "Epoch: 0027 loss = 0.128219\n",
            "Epoch: 0028 loss = 0.132057\n",
            "Epoch: 0029 loss = 0.125822\n",
            "Epoch: 0030 loss = 0.125888\n",
            "Epoch: 0031 loss = 0.125317\n",
            "Epoch: 0032 loss = 0.121148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE_ccVN8dCY_"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00cYCxeAd6Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "outputId": "982d34fb-8b07-4d03-e03b-a45e516daa5b"
      },
      "source": [
        "n_layers = 4\n",
        "'''\n",
        "batch 1:\n",
        "[[1, 2, 3, 5, 0],\n",
        "[1, 2, 3, 4, 0]]\n",
        "'''\n",
        "temp_batch = 0\n",
        "plt.figure(figsize=(n_heads * 3, n_layers * 3 + 3))\n",
        "# encoder_attns: [n_layers, batch, n_heads, source_len, source_len]\n",
        "i = 0\n",
        "tokens = sentences[temp_batch][0].split()\n",
        "for layer in range(n_layers):\n",
        "  for head in range(n_heads):\n",
        "    i += 1\n",
        "    plt.subplot(n_layers, n_heads, i)\n",
        "\n",
        "    plt.title('Layer:{}, Head:{}'.format(layer+1, head+1))\n",
        "    if i % n_heads == 0:\n",
        "      cbar=True\n",
        "    else:\n",
        "      cbar=False\n",
        "    sns.heatmap(encoder_attns[layer][temp_batch][head].detach().numpy(), cmap='YlGnBu',\n",
        "            xticklabels=tokens, yticklabels=tokens, cbar=cbar, vmin=0, vmax=1);\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x1080 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGwqkd9s8uDK"
      },
      "source": [
        "def greedy_search(model, encoder_input, start_symbol=target_vocab['S']):\n",
        "  '''\n",
        "  One sentence.\n",
        "  '''\n",
        "\n",
        "  # init for decoder\n",
        "  encoder_output, encoder_self_attns = model.encoder(encoder_input)\n",
        "  decoder_input = torch.zeros(1, target_len).type_as(encoder_input.data)\n",
        "  next_symbol = start_symbol\n",
        "\n",
        "  for i in range(target_len):\n",
        "    decoder_input[0][i] = next_symbol\n",
        "    # decoder_output: [batch(1), target_len, d_model]\n",
        "    decoder_output, _, _ = model.decoder(decoder_input, encoder_input, encoder_output)\n",
        "    projected = model.projection(decoder_output) # [batch, target_len, target_vocab_len]\n",
        "    projected = projected.squeeze(0) # [target_len, target_vocab_len]\n",
        "    prob = projected.max(dim=1, keepdim=False)[1]\n",
        "    next_symbol = prob.data[i].item()\n",
        "\n",
        "  return decoder_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOuF-yAB0aan"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  encoder_input, _, _ = next(iter(data_loader))\n",
        "  greedy_decoder_input = greedy_search(model, encoder_input[0].view(1, -1))\n",
        "  predict, _, _, _ = model(encoder_input[0].view(1, -1), greedy_decoder_input)\n",
        "  predict = predict.data.max(1, keepdim=True)[1]\n",
        "  print(encoder_input[0], '->', [idx2word[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6QChze2u8iN"
      },
      "source": [
        "def beam_search(model, encoder_input, beam=3, start_symbol=target_vocab['S']):\n",
        "  '''\n",
        "  Beam search.\n",
        "  '''\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}