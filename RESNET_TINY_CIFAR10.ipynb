{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cnhzgb/MachineL/blob/main/RESNET_TINY_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hofQlMWWYHNt",
    "outputId": "2d415e4d-86ce-4623-a573-a088f9bec49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import ipdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from torchsummary import summary\n",
    "import time\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "device = torch.device(\"mps\")\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JyY7NuECDB4",
    "outputId": "cd231e71-78dc-4c31-8531-95054f4ac17e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 50000 torch.Size([100, 3, 32, 32]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) # transforms.RandomHorizontalFlip(), transforms.RandomGrayscale()\n",
    "dataset = datasets.CIFAR10(root=\"/Users/bin.guanb/code/MachineL/dataset/\", transform=trans, download=False, train=True) # 5W张图片, 10种分类\n",
    "loader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "batch_num,(image, label) = next(enumerate(loader))\n",
    "print(len(dataset.classes), len(dataset), image.shape, label.shape) # 10; 5W; 100,3,32,32; 100\n",
    "\n",
    "trans_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "dataset_test = datasets.CIFAR10(root=\"/Users/bin.guanb/code/MachineL/dataset/\", transform=trans_test, download=False, train=False) # 1W张图片\n",
    "loader_test = DataLoader(dataset_test, batch_size=100, shuffle=True)\n",
    "criterion_test = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Fm-vKBCpQ966"
   },
   "outputs": [],
   "source": [
    "# https://www.cnblogs.com/emanlee/p/17138634.html\n",
    "\n",
    "class Block(nn.Module):\n",
    "  def __init__(self, inc, n_chans):\n",
    "    super(Block, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(inc, n_chans, kernel_size=3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1)\n",
    "    self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(self.batch_norm(x))\n",
    "    x = self.conv2(x)\n",
    "    x = self.batch_norm(x)\n",
    "    return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(3,32,1,padding=0)\n",
    "        self.conv11 = Block(3,32)\n",
    "\n",
    "        self.conv20 = nn.Conv2d(32,64,1,padding=0)\n",
    "        self.conv21 = Block(32,64)\n",
    "\n",
    "        self.conv30 = nn.Conv2d(64,128,1,padding=0)\n",
    "        self.conv31 = Block(64,128)\n",
    "\n",
    "        self.conv40 = nn.Conv2d(128,256,1,padding=0)\n",
    "        self.conv41 = Block(128,256)\n",
    "\n",
    "        self.conv50 = nn.Conv2d(256,512,1,padding=0)\n",
    "        self.conv51 = Block(256,512)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*2*2, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out1 = self.conv10(x) # 32,32,32\n",
    "        out2 = self.conv11(x)\n",
    "        x = self.pool(F.relu(out1 + out2)) # ,32,16,16\n",
    "\n",
    "        out1 = self.conv20(x) # 64,16,16\n",
    "        out2 = self.conv21(x)\n",
    "        x = self.pool(F.relu(out1 + out2)) # ,64,8,8\n",
    "\n",
    "        out1 = self.conv30(x) # 128,8,8\n",
    "        out2 = self.conv31(x)\n",
    "        x = self.pool(F.relu(out1 + out2)) # 128,4,4\n",
    "\n",
    "        out1 = self.conv40(x) # 256,4,4\n",
    "        out2 = self.conv41(x)\n",
    "        x = self.pool(F.relu(out1 + out2)) # 256,2,2\n",
    "\n",
    "        out1 = self.conv50(x) # 512,2,2\n",
    "        out2 = self.conv51(x)\n",
    "        x = F.relu(out1 + out2)\n",
    "        \n",
    "        x = x.view(-1,512*2*2)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
    "\n",
    "#print(model)\n",
    "#summary(model, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "efm8ASvZX9DS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 batch:99 loss:1.48 mean:1.62 error:50/100 errorTotal:6004/10000 60.04% time:10.6\n",
      "epoch:1 batch:199 loss:1.29 mean:1.47 error:46/100 errorTotal:10837/20000 54.19% time:15.2\n",
      "epoch:1 batch:299 loss:1.09 mean:1.38 error:40/100 errorTotal:15188/30000 50.63% time:19.9\n",
      "epoch:1 batch:399 loss:1.09 mean:1.32 error:44/100 errorTotal:19233/40000 48.08% time:24.5\n",
      "epoch:1 batch:499 loss:1.00 mean:1.26 error:37/100 errorTotal:22996/50000 45.99% time:29.1\n",
      "epoch:2 batch:99 loss:0.98 mean:0.91 error:43/100 errorTotal:3286/10000 32.86% time:4.6\n",
      "epoch:2 batch:199 loss:0.89 mean:0.89 error:32/100 errorTotal:6352/20000 31.76% time:9.3\n",
      "epoch:2 batch:299 loss:0.71 mean:0.88 error:25/100 errorTotal:9385/30000 31.28% time:13.9\n",
      "epoch:2 batch:399 loss:0.62 mean:0.86 error:18/100 errorTotal:12210/40000 30.52% time:18.5\n",
      "epoch:2 batch:499 loss:0.76 mean:0.85 error:29/100 errorTotal:15130/50000 30.26% time:23.1\n",
      "epoch:3 batch:99 loss:0.51 mean:0.61 error:20/100 errorTotal:2120/10000 21.20% time:4.6\n",
      "epoch:3 batch:199 loss:0.68 mean:0.63 error:23/100 errorTotal:4377/20000 21.89% time:9.3\n",
      "epoch:3 batch:299 loss:0.73 mean:0.63 error:26/100 errorTotal:6641/30000 22.14% time:13.9\n",
      "epoch:3 batch:399 loss:0.72 mean:0.63 error:25/100 errorTotal:8936/40000 22.34% time:18.5\n",
      "epoch:3 batch:499 loss:0.66 mean:0.63 error:24/100 errorTotal:11138/50000 22.28% time:23.2\n",
      "epoch:4 batch:99 loss:0.43 mean:0.41 error:13/100 errorTotal:1454/10000 14.54% time:4.6\n",
      "epoch:4 batch:199 loss:0.48 mean:0.43 error:13/100 errorTotal:3024/20000 15.12% time:9.3\n",
      "epoch:4 batch:299 loss:0.38 mean:0.44 error:14/100 errorTotal:4620/30000 15.40% time:13.9\n",
      "epoch:4 batch:399 loss:0.39 mean:0.45 error:15/100 errorTotal:6285/40000 15.71% time:18.5\n",
      "epoch:4 batch:499 loss:0.43 mean:0.46 error:16/100 errorTotal:7975/50000 15.95% time:23.1\n",
      "epoch:5 batch:99 loss:0.19 mean:0.26 error:6/100 errorTotal:865/10000 8.65% time:4.6\n",
      "epoch:5 batch:199 loss:0.34 mean:0.27 error:10/100 errorTotal:1858/20000 9.29% time:9.3\n",
      "epoch:5 batch:299 loss:0.37 mean:0.29 error:13/100 errorTotal:2975/30000 9.92% time:13.9\n",
      "epoch:5 batch:399 loss:0.32 mean:0.30 error:12/100 errorTotal:4151/40000 10.38% time:18.5\n",
      "epoch:5 batch:499 loss:0.46 mean:0.31 error:19/100 errorTotal:5398/50000 10.80% time:23.1\n",
      "epoch:6 batch:99 loss:0.15 mean:0.16 error:5/100 errorTotal:525/10000 5.25% time:4.6\n",
      "epoch:6 batch:199 loss:0.24 mean:0.17 error:9/100 errorTotal:1136/20000 5.68% time:9.2\n",
      "epoch:6 batch:299 loss:0.15 mean:0.19 error:4/100 errorTotal:1914/30000 6.38% time:13.9\n",
      "epoch:6 batch:399 loss:0.11 mean:0.19 error:3/100 errorTotal:2652/40000 6.63% time:18.5\n",
      "epoch:6 batch:499 loss:0.22 mean:0.20 error:6/100 errorTotal:3456/50000 6.91% time:23.1\n",
      "epoch:7 batch:99 loss:0.14 mean:0.11 error:6/100 errorTotal:373/10000 3.73% time:4.6\n",
      "epoch:7 batch:199 loss:0.18 mean:0.12 error:8/100 errorTotal:816/20000 4.08% time:9.2\n",
      "epoch:7 batch:299 loss:0.10 mean:0.14 error:3/100 errorTotal:1390/30000 4.63% time:13.9\n",
      "epoch:7 batch:399 loss:0.21 mean:0.15 error:7/100 errorTotal:2014/40000 5.04% time:18.5\n",
      "epoch:7 batch:499 loss:0.22 mean:0.15 error:9/100 errorTotal:2618/50000 5.24% time:23.1\n",
      "epoch:8 batch:99 loss:0.13 mean:0.09 error:5/100 errorTotal:298/10000 2.98% time:4.6\n",
      "epoch:8 batch:199 loss:0.09 mean:0.09 error:3/100 errorTotal:648/20000 3.24% time:9.2\n",
      "epoch:8 batch:299 loss:0.09 mean:0.10 error:3/100 errorTotal:1081/30000 3.60% time:13.9\n",
      "epoch:8 batch:399 loss:0.05 mean:0.11 error:1/100 errorTotal:1550/40000 3.88% time:18.5\n",
      "epoch:8 batch:499 loss:0.19 mean:0.11 error:8/100 errorTotal:2018/50000 4.04% time:23.1\n",
      "epoch:9 batch:99 loss:0.06 mean:0.09 error:3/100 errorTotal:303/10000 3.03% time:4.6\n",
      "epoch:9 batch:199 loss:0.11 mean:0.08 error:3/100 errorTotal:549/20000 2.75% time:9.2\n",
      "epoch:9 batch:299 loss:0.14 mean:0.08 error:5/100 errorTotal:865/30000 2.88% time:13.9\n",
      "epoch:9 batch:399 loss:0.09 mean:0.09 error:3/100 errorTotal:1289/40000 3.22% time:18.5\n",
      "epoch:9 batch:499 loss:0.10 mean:0.10 error:5/100 errorTotal:1755/50000 3.51% time:23.2\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,10):\n",
    "  total_loss = []\n",
    "  errorTotal = 0\n",
    "  startTime = time.time()\n",
    "  for batch_idx, (img, label) in enumerate(loader):\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "    outputs = model(img)\n",
    "    loss = criterion(outputs, label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss.append(loss.item())\n",
    "    maxV,maxIdx = outputs.max(dim=1)\n",
    "    errorNum = torch.sum(torch.ne(maxIdx, label)).item()\n",
    "    errorTotal += errorNum\n",
    "\n",
    "    if(batch_idx % 100 == 99):\n",
    "      print(\"epoch:{} batch:{} loss:{:.2f} mean:{:.2f} error:{}/100 errorTotal:{}/{} {:.2f}% time:{:.1f}\".format(\n",
    "          epoch, batch_idx, loss, np.mean(total_loss), errorNum, errorTotal, (batch_idx+1)*100, errorTotal/(batch_idx+1),\n",
    "          time.time()-startTime))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNayIVzlT5r2PBFJ+MJ3IZ8",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
